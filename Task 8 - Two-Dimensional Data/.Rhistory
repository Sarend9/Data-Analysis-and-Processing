cat("\n")
}
cat("Число инверсий Q: ", Q, "\n\n")
# 3) Найдем коэффициент Ꚍ-Кендалла:
#
#    Коэффициент ранговой корреляции Кендалла Ꚍ (тау Кендалла, Kendall’s tau)
#    — это разница между количеством согласованных и несогласованных изменений в парах наблюдений,
#    нормированная на общее число таких пар:
#
#    Формула Ꚍ-Кендалла:
#
#        P-Q
#    Ꚍ = ———
#        P+Q
#    где:
#    • P — согласованные изменения: при переходе от одного наблюдения к другому значения обеих переменных изменяются в одну и ту же сторону;
#    • Q — несогласованные изменения, или инверсии.
#
#    Формула согласованных изменений P:
#
#        N*(N-1)
#    P = ——————— - Q
#           2
P <- (nrow(x5.tour)*(nrow(x5.tour)-1))/2 - Q; cat("Число согласованных изменений P: ", P, "\n\n")
T.Kendall <- (P-Q)/(P+Q);                     cat("Ꚍ-Кендалла: ", T.Kendall, "\n\n")
#    Ꚍ-Кендалла также меняется в пределах от –1 до 1 и равен 0 при отсутствии связи между переменными.
#    В отличие от Q Юла, знак Ꚍ-Кендалла имеет четкую интерпретацию: он указывает направление связи.
#    Так,
#         • положительный знак указывает на прямое соотношение переменных:     при возрастании значений одной другая также растёт;
#         • отрицательный знак коэффициента указывает на обратное соотношение: росту одной переменной соответствует снижение значений другой.
x1 <- read.csv("C:/Users/ak179/OneDrive/Магистратура/2 КУРС/1 СЕМЕСТР/Лекции (2 курс)/Язык R (шпоры и задачи)/Скрипты/Задание 8/pet_state.dat")
#    1.1) Посмотрим на первые 6 начальных наблюдений изначальной таблицы:
head(x1)
#         Структура всей таблицы:
str(x1)
x1$married <- factor(x1$married)
x1$pet     <- factor(x1$pet)
str(x1)
levels(x1$married) <- c("одинокий ", "в браке")
levels(x1$pet)     <- c("кошки ", "собаки")
#    1.4) Посмотрим структуру таблицы с факторами и проверим её:
str(x1)
#    1.2) Изменим формат столбцов таблицы с числового на номинальный.
#         Для этого переведем векторы из числового разряда в фактор,
#         т.е. уровни "0" и "1" будут закодированы в виде чисел (1 и 2).
x1$married <- factor(x1$married)
#    1.4) Посмотрим структуру таблицы с факторами и проверим её:
str(x1)
#         Сводка по таблице:
summary(x1)
x1 <- na.omit(x1); summary(x1)
x1.tbl <- table(x1); x1.tbl
x1.tbl <- t(x1.tbl); x1.tbl
# -/ОБЩАЯ ТЕОРИЯ/-
# ----------------
# Установить, какая из переменных влияет на другую, т.е. выявить, какая из них — причина,
# а какая — следствие, статистическими методами невозможно в принципе.
#
# Статистический анализ позволяет выявить лишь само наличие связи,
# описать её выраженность и некоторые другие формальные характеристики.
# На вопрос о том, как установить, что обнаруженная связь — это именно влияние, т.е. между
# переменными существуют причинно-следственные отношения, отвечает «планирование эксперимента»
OR.Q <- function(x, transposition = FALSE) {
# -/ИНСТРУКЦИЯ/-
# x - либо может быть обычной таблицей с 2 колонками. либо сразу таблицей сопряженности.
# transposition - нужно ли траспонировать таблицу сопряженности (на результат не влияет!)
# 1) Для нормальной работы с данными следует избавиться от пропущенных строк (избавимся от NA):
if (((is.data.frame(x)) | (is.numeric(x))) & !is.table(x)) {
x <- na.omit(x)
#    -/ПРИМЕЧАНИЕ/-:
#    Функция "na.omit(x)" выдаёт исходный объект x, целиком опуская (omit)
#    строки с пропусками хотя бы по одной переменной.
# 2) Таблица сопряжённости:
#    2.1) Составим таблицу сопряжённости по нашим данным:
x <- table(x)}
#                                               |   В данной таблице сопряжённости две ГРАДАЦИИ:
#         -/ПРИМЕР/-:                           |     • переменной (pet) по строкам - "кошки" и "собаки"
#                              married          |     • переменной (married) по столбцам  - "одинокий" и "в браке"
#                                               |   По столбцам; соответствующие частоты обозначили буквами a, b, c, d.
#                      | одинокий | в браке |   |
#               ------------------------------  |   Т.е. такие переменные называются БИНАРНЫМИ.
#               кошки  |    a     |    b    |   |   В случае двух бинарных переменных в таблице сопряжённости
#         pet   ------------------------------  |   оказывается четыре ячейки, или поля.
#               собаки |    c     |    d    |   |
#                                               |   Её так и называют — четырёхпольной (fourfold),
#                                               |   или таблицей 2 × 2 (two by two table).
#
#         Симметричное отображение таблицы с помощью функции t() относительно диагонали.
if(transposition == TRUE) {
x <- t(x); cat("Таблица сопряженности (т): \n"); cat("-------------------------------------------------------"); cat("\n"); print(x); cat("-------------------------------------------------------" ,"\n"); cat("\n\n")
} else {   cat("Таблица сопряженности:\n");      cat("-------------------------------------------------------"); cat("\n"); print(x); cat("-------------------------------------------------------" ,"\n"); cat("\n\n")}
#  3) Найдем:
#    • отношение шансов OR;
#    • коэффициент Q Юла (модуль).
#
#    3.1) Отношение шансов OR:
#
#         Если обе переменные БИНАРНЫ, меру их связи легко получить,
#         соотнеся шансы какого-нибудь из значений одного признака при
#         разных значениях второго.
#
#         Пример поиска OR:
#                                               |                    | Так, мы можем сравнить шансы:
#                              married          |                    |  • a/c - увидеть кого-то c питомцем кошкой, наблюдая только за одинокими,
##                                              | Формула шансов OR: |  • b/d — только за тех, кто в браке.
#                      | одинокий | в браке |   |                    |
#               ------------------------------  |      a/c   a*d     |
#               кошки  |    a     |    b    |   | OR = ——— = ———     | Сравнить шансы можно, вычислив их отношение — мы получим меру связи,
#         pet   ------------------------------  |      b/d   b*c     | которая так и называется: отношение шансов (Odds Ratio, OR)
#               собаки |    c     |    d    |   |                    | В последнем виде проясняется смысл отношения шансов (ad/bc).
#                                               |                    |
#
#        ad и bc — это диагонали таблицы 2 × 2, на которых представлены
#        противоположные закономерности, так:
#                                        • a — "одиночки" с питомцами кошками;
#                                        • d — "в браке"  с питомцами собаками.
#
#        Если все наблюдения попадают на диагональ ad, то это полная,
#        однозначная детерминистическая связь: у "одиночек" питомцы всегда являются кошками.
#
#        Диагональ bc представляет обратную закономерность: питомцы являются кошками всегда у тех, кто "в браке".
a <- x[1,1];  b <- x[1,2]
c <- x[2,1];  d <- x[2,2]
cat ("Тенденции:", "\n")
cat("-------------------------------------------------------" ,"\n")
cat( "• диагональ ad - тенденция:",
"(", as.character((as.data.frame(x))[[1]])[1], "/", as.character((as.data.frame(x))[[2]])[1],"=", a, ")",
"и",
"(", as.character((as.data.frame(x))[[1]])[4], "/", as.character((as.data.frame(x))[[2]])[4],"=", d, ")")
cat("\n")
cat( "• диагональ bc - тенденция:",
"(", as.character((as.data.frame(x))[[1]])[3], "/", as.character((as.data.frame(x))[[2]])[3],"=", b, ")",
"и",
"(", as.character((as.data.frame(x))[[1]])[2], "/", as.character((as.data.frame(x))[[2]])[2],"=", c, ")")
cat("\n")
cat("-------------------------------------------------------" ,"\n")
cat("\n\n")
# Отношение шансов OR:
OR <- (a/c)/(b/d)
#    3.2) коэффициент Q Юла (модуль):
#
#                                 |  Отношение шансов хорошо свой простотой и понятностью, но имеет и недостатки.
#         Формула:                |  и недостатки. Когда связи нет, т.е. она равна нулю, OR = 1. Кроме
##                                |  того, OR несимметрично: в меньшую сторону оно изменяется в
#             OR - 1   ad - bc    |  пределе до нуля, а в большую — до бесконечности. Эти недостатки
#         Q = —————— = ———————    |  устраняются простым математическим фокусом: делим OR на само
#             OR + 1   ad + bc    |  себя, при этом из числителя вычитаем единицу, а к знаменателю —
##                                |  наоборот, прибавляем.
#
#         ad - тенденция, что те, кто одиноки с питомцем кошкой и те, кто в браке с питомцем собакой
#         bc - тенденция, что те, кто в браке с питомцем кошкой и те, кто одиноки с питомцем собакой
#
#         Если тенденции одинаковы, то получаем 0, если какая-то преобладает, то получаем 1 или -1.
#
#         Коэффициент Q:
Q <- (OR-1)/(OR+1)
if (Q > 0) {trend <- "тенденция «ad» преобладает над тенденцией «bc»"}
if (Q < 0) {trend <- "тенденция «bc» преобладает над тенденцией «ad»"}
# 4) Интепретация:
#    Таблица РАЗМЕРА ЭФФЕКТА:
#    ------------------------
#    модуль коэффициента	связь
#    <    0.10	не выражена
#    ≥    0.10	слабая
#    ≥    0.30	умеренная
#    ≥    0.50	тесная
#    В таблице приведены ориентировочные, достаточно условные уровни размера эффекта, предложенные Джейкобом Коэном (Cohen, 1988).
if  (abs(Q) <  0.10)                    {power.com <- "не выражена"}
if ((abs(Q) >= 0.10) & (abs(Q) < 0.30)) {power.com <- "слабая"     }
if ((abs(Q) >= 0.30) & (abs(Q) < 0.50)) {power.com <- "умеренная"  }
if  (abs(Q) >= 0.50)                    {power.com <- "тесная"     }
cat('Сила связи между', '\033[1m', names(as.data.frame(x)[1]), '\033[0;0m',
'и', '\033[1m', names(as.data.frame(x)[2]), '\033[0;0m', ":","\n")
cat("-------------------------------------------------------"   ,"\n")
cat("• OR - отношение шансов: ", OR                             ,"\n")
cat("• коэффициент Q Юла:     ", Q                              ,"\n")
cat("-------------------------------------------------------"   ,"\n")
cat("• Вывод: 1) обнаружена ", '\033[1m', power.com ,'\033[0;0m', "связь",
'\x1B[3m', names(as.data.frame(x)[1]), '\x1B[23m',
"с",
'\x1B[3m', names(as.data.frame(x)[2]), '\x1B[23m')
cat("\n")
cat("         2)", trend)
cat("\n")
cat("-------------------------------------------------------" ,"\n")
}
Cramer.V <- function(x){
# 1) Найдем:
#    • [Теоретически] ожидаемые частоты;
#    • χ2 Пирсона;
#    • V  Крамера.
#    1.1) [Теоретически] ожидаемые частоты для модели НЕЗАВИСИМЫХ признаков:
#         1.1.1) Для нормальной работы с данными следует избавиться от пропущенных строк (избавимся от NA):
if (((is.data.frame(x)) | (is.numeric(x))) & !is.table(x)) {
x <- na.omit(x)
#         1.1.1) Составим таблицу сопряжённости:
x <- table(x)}
cat("Таблица сопряжённости:"); cat("\n")
cat("-------------------------------------------------------"); cat("\n")
print(x)
cat("-------------------------------------------------------"); cat("\n"); cat("\n")
#         1.1.2) Переведём в относительные частоты:
relat.x.tbl <- x/sum(x)
#                -/ПРИМЕЧАНИЕ/-:
#                Функция length() не подойдет, т.к. посчитает количество стобцов,
#                поэтому используем nrow() для получения количества строк.
#                Так же можно использовать sum() от таблицы сопряжённости.
#         1.1.3) Находим распределение вероятностей независимых признаков (вектора МАРГИНАЛЬНЫХ частот):
marg.rows <- vector()                                # создаем пустой вектор
marg.rows <- apply(relat.x.tbl, MARGIN = 1, FUN = sum)# суммы по строкам
marg.cols <- apply(relat.x.tbl, MARGIN = 2, FUN = sum)# суммы по столбцам
#                -/ПОЯСНЕНИЕ/-:
#                Что мы нашли? МАРГИНАЛЬНЫЕ ЧАСТОТЫ - marg.rows и marg.cols, слово МАРГИНО - записки на полях
#                          |   ВКонтакте  | Одноклассники |   Фейсбук    |
#                -----------------------------------------------------------------------
#                mail.ru   |              |               |              |  marg.rows[1]
#                -----------------------------------------------------------------------
#                yandex.ru |              |               |              |  marg.rows[2]
#                -----------------------------------------------------------------------
#                gmail.com |              |               |              |  marg.rows[3]
#                -----------------------------------------------------------------------
#                          | marg.cols[1] |  marg.cols[4] | marg.cols[3] |      1
#         1.1.4) По маргинальным частотам вычисляем ОТНОСИТЕЛЬНЫЕ частоты для "РАСПРЕДЕЛЕНИЯ НЕЗАВИСИМЫХ ПРИЗНАКОВ":
#                (это попарные произведения маргинальных относительных частот одной и другой переменных).
model.prob <- marg.rows %o% marg.cols # (еще оно называется - внешнее произведение векторов)
#                -/ПРИМЕЧАНИЕ/-:
#                Операция " %o% " попарно перемножает каждый элемент одного вектора
#                на все элементы другого (такое произведение называется внешним).
#                -/ПОЯСНЕНИЕ/-:
#                Пример того, как выглядит перемножение:
#                          |          ВКонтакте          |        Одноклассники        |           Фейсбук           |
#                -------------------------------------------------------------------------------------------------------------------
#                mail.ru   | marg.rows[1] * marg.cols[1] | marg.rows[1] * marg.cols[2] | marg.rows[1] * marg.cols[3] |  marg.rows[1]
#                -------------------------------------------------------------------------------------------------------------------
#                yandex.ru | marg.rows[2] * marg.cols[1] | marg.rows[2] * marg.cols[2] | marg.rows[2] * marg.cols[3] |  marg.rows[2]
#                -------------------------------------------------------------------------------------------------------------------
#                gmail.com | marg.rows[3] * marg.cols[1] | marg.rows[3] * marg.cols[2] | marg.rows[3] * marg.cols[3] |  marg.rows[3]
#                -------------------------------------------------------------------------------------------------------------------
#                          |          marg.cols[1]       |          marg.cols[4]       |          marg.cols[3]       |      1
#         1.1.5) Переводим ожидаемые ОТНОСИТЕЛЬНЫЕ частоты в АБСОЛЮТНЫЕ, умножая model.prob
#                на объём наблюдений, и сохраняем результат как model.freq
model.freq <- model.prob * sum(x)
cat("[Теоретические] ожидаемые частоты для модели независимости признаков:"); cat("\n")
cat("-------------------------------------------------------"); cat("\n")
print(model.freq)
cat("-------------------------------------------------------"); cat("\n"); cat("\n")
#    1.2) χ2 Пирсона (квадраты стандартизованных остатков):
#         Сравним полученные "эмпирическое" и "теоретическое" распределения [абсолютных] частот,
#
#         Формула χ2 Пирсона:   |
#                               |  где:
#              k  (Oᵢ - Eᵢ)²    |  • Oᵢ - эмпирически наблюдаемая  (Observed) частота;
#         χ2 = Σ  ——————————    |  • Eᵢ - [теоретически] ожидаемая (Expected) частота;
#             i=1     Eᵢ        |  • разницу между "Observed" и "Expected" называют остатком (residual).
Pirs.X2 <- sum(((x - model.freq)**2)/model.freq)
#    1.3) V Крамера:
#         У χ2 Пирсона так же, как у OR, есть недостатки: он может изменяться
#         в пределах [0 : бесконечности], в зависимости от объёма наблюдений
#         и от числа градаций признаков.
#         Эти неудобства устраняют, нормируя χ2 на N и внося некоторые поправки — так
#         получают новые меры связи, например, коэффициент V Крамера (Cramér’s V):
#         V Крамера принимает значения:
#          • ОТ "0" - при полном отсутствии связи между переменными
#          • ДО "1" - при полной функциональной связи.
#         Формула V Крамера:
#
#                                         |  где:
#                    x²                   |  • l — меньшее из ГРАДАЦИЙ (количеств строк r и столбцов) c в таблице сопряжённости;
#         Vc = √(————————); l = min(r,c)  |  т.е. из таблицы 3X2 l=2, таблицы 5X3 l=3 и т.п.
#                 N(l-1)                  |
Cram.V <- sqrt(Pirs.X2/(sum(x)*(min(c(nrow(model.freq), (ncol(model.freq))))-1)))
# 2) Интепретация:
#    Таблица РАЗМЕРА ЭФФЕКТА:
#    ------------------------
#    модуль коэффициента	связь
#    <    0.10	не выражена
#    ≥    0.10	слабая
#    ≥    0.30	умеренная
#    ≥    0.50	тесная
#    В таблице приведены ориентировочные, достаточно условные уровни размера эффекта, предложенные Джейкобом Коэном (Cohen, 1988).
if  (abs(Kram.V) <  0.10)                         {power.com <- "не выражена"}
if ((abs(Kram.V) >= 0.10) & (abs(Kram.V) < 0.30)) {power.com <- "слабая"     }
if ((abs(Kram.V) >= 0.30) & (abs(Kram.V) < 0.50)) {power.com <- "умеренная"  }
if  (abs(Kram.V) >= 0.50)                         {power.com <- "тесная"     }
cat('Сила связи между', '\033[1m', names(as.data.frame(x)[1]), '\033[0;0m',
'и', '\033[1m', names(as.data.frame(x)[2]), '\033[0;0m', ":"          ,"\n")
cat("-------------------------------------------------------"             ,"\n")
cat("• коэффициент χ2 Пирсона:", Pirs.X2                                  ,"\n")
cat("• коэффициент V  Крамера:", Cram.V                                   ,"\n")
cat("-------------------------------------------------------"             ,"\n")
cat("• Вывод: обнаружена ", '\033[1m', power.com ,'\033[0;0m', "связь",
'\x1B[3m', names(as.data.frame(x)[1]), '\x1B[23m',
"с",
'\x1B[3m', names(as.data.frame(x)[2]), '\x1B[23m');                cat("\n")
cat("-------------------------------------------------------"             ,"\n")
}
Kendall.T <- function(x, full.print=FALSE){
# 2) Найдем число инверсий Q;
#    2.1) Для удобства подсчёта сначала упорядочим наблюдения по возрастанию первой переменной,
#         и далее будем анализировать только вторую
i <- order(x[ , 1]); i# вектор номеров строк, упорядоченных по 1-му столбцу
#         -/ПРИМЕЧАНИЕ/-:
#         ---------------
#         Функция "order()" выдаёт номера всех строк таблицы experts
#         в порядке возрастания значений столбца, указанного в фильтре
#         -/ПРИМЕР order()/-:
#         -------------------
#         Команда x[ , 1] выведет вектор tour.1, но у него есть порядок, определяемый индексами:
#         индекс : 1 2 3 4 5 6 7 8
#         tour.1 : 7 5 3 4 6 1 2 8
#         Если значения x[ , 1] условно для себя представить в остортированном порядке,
#         то индексы будут расположены следующим образом:
#         индекс : 6 7 3 4 2 5 1 8
#         tour.1 : 1 2 3 4 5 6 7 8
#         Команда order(x[ , 1]) как раз и выведет эти индексы:
#         i <- order(x[ , 1]) - это: 6 7 3 4 2 5 1 8
#    2.2) Отсортируем таблицу так, чтобы вектор номеров i задал новый порядок следования строк x
x <- x[i, ]; x # строки таблицы в новом порядке
#    2.3) Напишем цикл для подсчета инверсий:
#         При полном совпадении столбцов её значения должны
#         также выстроиться в порядке возрастания, т.е. при попарном сравнении строк
#         значение ВЕРХНЕЙ строки всегда должно быть МЕНЬШИМ, чем НИЖНИЕЙ строки.
#         Если, наоборот, меньшим оказывается значение нижней строки,
#         то мы получаем несогласованное изменение — инверсию.
#         Код ниже написин таким образом, что в консоле отобразит полностью свою работу:
if (full.print==TRUE){
cat("Таблица x: ", "\n\n"); t(x)
Q <- numeric(1); P <- numeric(1)
for (i in 1:(nrow(x) - 1)) {
cat('\033[1m', i, "цикл:", '\033[0;0m', "\n");                                         cat("--------------------------------------------","\n")
#         сохраняем столбец в отдельный вектор
x.i  <- x[i:nrow(x), 2];                              cat("значения второй переменной:", x.i,  "\n");                                        cat("--------------------------------------------","\n")
#         извлекаем только наблюдения, меньшие и больше первого
inversionsQ   <- x.i[x.i < x.i[1]];                   cat("inversions   Q            :","меньше", x.i[1], "только:", inversionsQ   ,"\n");  cat("--------------------------------------------","\n")
coincidencesP <- x.i[x.i > x.i[1]];                   cat("coincidences P            :","больше", x.i[1], "только:", coincidencesP ,"\n");  cat("--------------------------------------------","\n")
#         объём этих наблюдений, т.е. число инверсий
Q1 <- Q + length(inversionsQ);                        cat("число инверсий   Q        :", Q1, "(",Q,"+",length(inversionsQ)  ,")","\n");     cat("--------------------------------------------","\n");
P1 <- P + length(coincidencesP);                      cat("число совпадений P        :", P1, "(",P,"+",length(coincidencesP),")","\n");     cat("--------------------------------------------","\n"); cat("\n");
Q <- Q1; P<-P1
}
}else{
Q <- numeric(1)
for (i in 1:(nrow(x) - 1)) {
x.i  <- x[i:nrow(x), 2]           # сохраняем столбец в отдельный вектор
inversions <- x.i[x.i < x.i[1]]   # извлекаем только наблюдения, меньшие первого
Q <- Q + length(inversions)       # объём этих наблюдений, т.е. число инверсий
}
}
# 3) Найдем коэффициент Ꚍ-Кендалла:
#
#    Коэффициент ранговой корреляции Кендалла Ꚍ (тау Кендалла, Kendall’s tau)
#    — это разница между количеством согласованных и несогласованных изменений в парах наблюдений,
#    нормированная на общее число таких пар:
#
#    Формула Ꚍ-Кендалла:
#
#        P - Q    |    где:
#   𝛕 = —————    |    • P — согласованные изменения: при переходе от одного наблюдения к другому значения обеих переменных изменяются в одну и ту же сторону;
#        P + Q    |    • Q — несогласованные изменения, или инверсии.
#
#
#    Формула согласованных  | Формула (P) выведена из:
#    изменений P:           |
#                           |
#        N*(N-1)            |           N*(N-1)
#    P = ——————— - Q        |   P + Q = ———————
#           2               |              2
P <- (nrow(x)*(nrow(x)-1))/2 - Q
T.Kendall <- (P-Q)/(P+Q)
#    Ꚍ-Кендалла также меняется в пределах  [–1 : 1] и равен 0 при отсутствии связи между переменными.
#    В отличие от Q Юла, знак Ꚍ-Кендалла имеет четкую интерпретацию: он указывает НАПРАВЛЕНИЕ связи.
#    Так,
#         • (+) положительный знак указывает на прямое соотношение переменных:     при возрастании значений одной другая также растёт;
#         • (-) отрицательный знак коэффициента указывает на обратное соотношение: росту одной переменной соответствует снижение значений другой.
# 4) Интепретация:
#    Таблица РАЗМЕРА ЭФФЕКТА:
#    ------------------------
#    модуль коэффициента	связь
#    <    0.10	не выражена
#    ≥    0.10	слабая
#    ≥    0.30	умеренная
#    ≥    0.50	тесная
#    В таблице приведены ориентировочные, достаточно условные уровни размера эффекта, предложенные Джейкобом Коэном (Cohen, 1988).
if  (abs(T.Kendall) <  0.10)                            {power.com <- "не выражена"}
if ((abs(T.Kendall) >= 0.10) & (abs(T.Kendall) < 0.30)) {power.com <- "слабая"     }
if ((abs(T.Kendall) >= 0.30) & (abs(T.Kendall) < 0.50)) {power.com <- "умеренная"  }
if  (abs(T.Kendall) >= 0.50)                            {power.com <- "тесная"     }
# наблюдения - то что по строкам, прим:   index tour.1 tour.2
#                                           3     3      3
# переменные - столбцы.
cat('Сила связи между переменными:', '\033[1m', names(as.data.frame(x)[1]), '\033[0;0m',
'и', '\033[1m', names(as.data.frame(x)[2]), '\033[0;0m', ":"                            ,"\n")
cat("-------------------------------------------------------------"                         ,"\n")
cat("• коэффициент Ꚍ Кендалла:", T.Kendall                    ,"\n")
cat("• Q - число инверсий    :", Q                            ,"\n")
cat("• P - число совпадений  :", P                            ,"\n")
cat("-------------------------------------------------------------"                         ,"\n")
if (T.Kendall>0){
cat("• Вывод: 1) Ꚍ Кендалла", '\033[1m',  "положителен,",'\033[0;0m', "значит, связь между", "\n")
cat("            переменными (корреляция)", '\033[1m',  "прямая,",'\033[0;0m',"т.е. в ",     "\n")
cat("            наблюдениях чаще совпадения, чем расхождения\n")}
if (T.Kendall<0){
cat("• Вывод: 1) Ꚍ Кендалла", '\033[1m',  "отрицателен,",'\033[0;0m', "значит, связь между", "\n")
cat("            переменными (корреляция)", '\033[1m',  "обратная",'\033[0;0m',"т.е. в ",    "\n")
cat("            наблюдениях чаще расхождения, чем совпадения\n")}
cat("\n")
cat("         2)",paste0("Ꚍ Кендалла = ", round(T.Kendall, 7), ", значит, что, беря наугад"),"\n")
cat("            две пары наблюдений, мы обнаружим в наблюдениях: \n")
cat("            • совпадение  в", paste0(round((0.5+(T.Kendall/2))*100,1), "%"), "случаев,   \n")
cat("            • расхождение в", paste0(round((0.5-(T.Kendall/2))*100,1), "%"), "случаев.   \n")
cat("\n")
cat("         3) Обнаружена ", '\033[1m', power.com ,'\033[0;0m', "связь",
'\x1B[3m', names(as.data.frame(x)[1]), '\x1B[23m',
"с",
'\x1B[3m', names(as.data.frame(x)[2]), '\x1B[23m');          cat("\n")
cat("-------------------------------------------------------------" ,"\n")
# a.	Установить, какая из переменных влияет на другую статистическими методами невозможно в принципе. Статистический анализ позволяет выявить лишь само наличие связи, описать её выраженность и некоторые другие формальные характеристики. Т.е. QЮла>0.10 показывает лишь то, что есть слабая зависимость между переменными.
# b.	А вот экспертный метод, например, ранговая корреляция позволяет определить влияние и направление корреляционной связи между двумя переменными.
}
# Вопрос 5: Восемь команд участвовали в двух турах соревнований;
#           данные о занятых ими местах в каждом туре записаны в отдельных файлах:
x5.tour.1 <- read.csv("C:/Users/ak179/OneDrive/Магистратура/2 КУРС/1 СЕМЕСТР/Лекции (2 курс)/Язык R (шпоры и задачи)/Скрипты/Задание 8/5_6.tour.1.dat")
x5.tour.2 <- read.csv("C:/Users/ak179/OneDrive/Магистратура/2 КУРС/1 СЕМЕСТР/Лекции (2 курс)/Язык R (шпоры и задачи)/Скрипты/Задание 8/5_6.tour.2.dat")
# Задача:
# • определите, насколько схожими оказались позиции команд в двух турах, найдя τ Кендалла;
# • Введите число инверсий Q.
# Решение:
# 1)  Составим из двух отдельных таблиц одну общую:
x5.tour <- cbind(x5.tour.1, x5.tour.2); x5.tour
# 2) Найдем число инверсий Q;
#    2.1) Для удобства подсчёта сначала упорядочим наблюдения по возрастанию первой переменной,
#         и далее будем анализировать только вторую
i <- order(x5.tour[ , 1]); i  # вектор номеров строк, упорядоченных по 1-му столбцу
#         -/ПРИМЕЧАНИЕ/-:
#         ---------------
#         Функция "order()" выдаёт номера всех строк таблицы experts
#         в порядке возрастания значений столбца, указанного в фильтре
#         -/ПРИМЕР order()/-:
#         -------------------
#         Команда x5.tour[ , 1] выведет вектор tour.1, но у него есть порядок, определяемый индексами:
#         индекс : 1 2 3 4 5 6 7 8
#         tour.1 : 7 5 3 4 6 1 2 8
#         Если значения x5.tour[ , 1] условно для себя представить в остортированном порядке,
#         то индексы будут расположены следующим образом:
#         индекс : 6 7 3 4 2 5 1 8
#         tour.1 : 1 2 3 4 5 6 7 8
#         Команда order(x5.tour[ , 1]) как раз и выведет эти индексы:
#         i <- order(x5.tour[ , 1]) - это: 6 7 3 4 2 5 1 8
#    2.2) Отсортируем таблицу так, чтобы вектор номеров i задал новый порядок следования строк x5.tour
x5.tour <- x5.tour[i, ]; x5.tour  # строки таблицы в новом порядке
#    2.3) Напишем цикл для подсчета инверсий:
#         При полном совпадении туров её значения должны
#         также выстроиться в порядке возрастания, т.е. при попарном сравнении строк
#         значение ВЕРХНЕЙ строки всегда должно быть МЕНЬШИМ, чем НИЖНИЕЙ строки.
#         Если, наоборот, меньшим оказывается значение нижней строки,
#         то мы получаем несогласованное изменение — инверсию.
#         Код ниже написин таким образом, что в консоле отобразит полностью свою работу:
cat("Таблица x5.tour: ", "\n\n"); t(x5.tour)
Q <- numeric(1)
for (i in 1:nrow(x5.tour) - 1) {
cat('\033[1m', i+1, "цикл:", '\033[0;0m', "\n");                            cat("------------------------------------------","\n")
# сохраняем столбец в отдельный вектор
x5.tour.i  <- x5.tour[i:nrow(x5.tour), 2];               cat("x5.tour.i  : ", x5.tour.i,  "\n");                                     cat("------------------------------------------","\n")
# извлекаем только наблюдения, меньшие первого
inversions <- x5.tour.i[x5.tour.i < x5.tour.i[1]];       cat("inversions : ","меньше", x5.tour.i[1], "только:", inversions  ,"\n");  cat("------------------------------------------","\n")
# объём этих наблюдений, т.е. число инверсий
Q1          <- Q + length(inversions);                   cat("Q          : ", Q1, "(",Q,"+ length(",inversions,")",")","\n");        cat("------------------------------------------","\n"); cat("\n");
Q <- Q1
};cat("Число инверсий Q: ", Q, "\n\n")
# 3) Найдем коэффициент Ꚍ-Кендалла:
#
#    Коэффициент ранговой корреляции Кендалла Ꚍ (тау Кендалла, Kendall’s tau)
#    — это разница между количеством согласованных и несогласованных изменений в парах наблюдений,
#    нормированная на общее число таких пар:
#
#    Формула Ꚍ-Кендалла:
#
#        P - Q    |    где:
#   𝛕 = —————    |    • P — согласованные изменения: при переходе от одного наблюдения к другому значения обеих переменных изменяются в одну и ту же сторону;
#        P + Q    |    • Q — несогласованные изменения, или инверсии.
#
#
#    Формула согласованных  | Формула (P) выведена из:
#    изменений P:           |
#                           |
#        N*(N-1)            |           N*(N-1)
#    P = ——————— - Q        |   P + Q = ———————
#           2               |              2
P <- (nrow(x5.tour)*(nrow(x5.tour)-1))/2 - Q; cat("Число согласованных изменений P: ", P, "\n\n")
T.Kendall <- (P-Q)/(P+Q);                     cat("Ꚍ-Кендалла: ", T.Kendall, "\n\n")
#    Ꚍ-Кендалла также меняется в пределах  [–1 : 1] и равен 0 при отсутствии связи между переменными.
#    В отличие от Q Юла, знак Ꚍ-Кендалла имеет четкую интерпретацию: он указывает НАПРАВЛЕНИЕ связи.
#    Так,
#         • (+) положительный знак указывает на прямое соотношение переменных:     при возрастании значений одной другая также растёт;
#         • (-) отрицательный знак коэффициента указывает на обратное соотношение: росту одной переменной соответствует снижение значений другой.
# Интерпретируйте результаты анализа, руководствуясь таблицей РАЗМЕРА ЭФФЕКТА:
# модуль коэффициента	связь
#   <    0.10	не выражена
#   ≥    0.10	слабая
#   ≥    0.30	умеренная
#   ≥    0.50	тесная
# 1)
# Ꚍ-Кендалла положителен, значит, связь между переменными (корреляция) прямая,
# т.е.чаще происходят совпадения в наблюдениях, чем отличия.
# Ꚍ = 0.2142857 значит, что, беря наугад позиции 2 команд в 2 турах (две пары наблюдений),
# мы обнаружим совпадения результатов туров в 60.8% случаев, а расхождение, а расхождение, в 39.2%.
# 2)
# a.	Установить, какая из переменных влияет на другую статистическими методами невозможно в принципе. Статистический анализ позволяет выявить лишь само наличие связи, описать её выраженность и некоторые другие формальные характеристики. Т.е. QЮла>0.10 показывает лишь то, что есть слабая зависимость между переменными.
# b.	А вот экспертный метод, например, ранговая корреляция позволяет определить влияние и направление корреляционной связи между двумя переменными.
x123 <- data.frame(exp.1 = c(1,2,3,4,9,8,7,10,5,6), exp.2 = c(1,4,3,2,9,8,7,10,5,6))
x123
Kendall.T(x123, T)
