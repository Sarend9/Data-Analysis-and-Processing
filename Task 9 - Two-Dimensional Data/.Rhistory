#         Такая нелинейная связь называется - МОНОТОННОЙ.
#
#         Нелинейная монотонная связь
#          _______________________
#         |*                      |     Функция - МОНОТОННАЯ, если направление изменения одной переменной
#         |*                      |     не меняется с возрастанием (убыванием) другой переменной.
#         |*                      |
#         |*                      |     Монотонная связь может быть:
#         |  *                    |     ----------------------------
#         |  *                    |     • либо неубывающей;
#         |    *                  |     • либо невозрастающей.
#         |    *                  |
#         |      *                |     Несмотря такую полную связь, на отсутствие разброса точек вокруг воображаемой линии,
#         |        * *            |     коэффициент их линейной корреляции вновь оказывается по модулю значительно меньше единицы.
#         |            * *        |
#         |                * * * *|     При монотонной связи часто распределения переменных имеют выраженную асимметрию, причём её знаки различаются.
#          ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#    1.4) Определяем ИНДЕКСЫ точек интерактивно по графику:
identify(x3)  # интерактивное определение индексов точек
#    1.5) Очистим таблицу данных от этих наблюдений (выбросов):
x3.clean <- x3[-c(31, 33), ]
# 2) Вычислите меры связи количества вспомненного материала с временем,
#    прошедшим с момента его запоминания при помощи:
#    • коэффициента ρ (коэффициент линейной корреляции ρ Пирсона);
#    • коэффициента ρs коэффициент ранговой корреляции ρs Спирмена).
#
#    2.1) Коэффициент ρ Пирсона:
P_x.y <- function(x.table)
{
x.table <- na.omit(x.table)
sd_x    <- sqrt(sum((x.table[[1]] - mean(x.table[[1]]))^2)/nrow(x.table))
sd_y    <- sqrt(sum((x.table[[2]] - mean(x.table[[2]]))^2)/nrow(x.table))
Σ       <- sum((x.table[[1]]-mean(x.table[[1]]))*(x.table[[2]]-mean(x.table[[2]])))
N.σx.σy <- nrow(x.table)*sd_x*sd_y
return(Σ/N.σx.σy)
}
P_x.y(x3.clean) # - коэффициент ρ для очищенных данных
P_x.y(x3)       # - Коэффициент ρ для данных с выбросами
#         -/ПРИМЕЧАНИЕ/-:
#         Коэффцицент кореляции здесь вышел сильно заниженным, хотя точки почти идут ровно по линии.
#         Это говорит о том, что здесь применялась неправильная мера для данного распределения.
#    2.2) Коэффициент ρs Спирмена:
#
#         Для того, чтобы правильно применить коэффициент кореляции, нужно выпрямить наши данные.
#         Т.е. нужно искуственно выпрямляем распределение, чтобы она налезала на одну прямую и считаем коэффициент корреляции.
#
#         Простой способ избавиться от асимметрии — перевести значения наблюдений каждой переменной в ранги:
#         так мы получим практически равномерные распределения вида “1, 2, 3, 4 …,”
#         где каждое значение будет встречаться лишь однажды, за исключением связанных рангов.
#
x3.clean.rang <- data.frame(rememb = rank(x3.clean$rememb),
time   = rank(x3.clean$time))
(head(x3.clean.rang))
# Сразу делаем ранги для данных с выбросами
x3.rang       <- data.frame(rememb = rank(x3$rememb),
time   = rank(x3$time))
#         Затем вычислим коэффициент корреляции по той же формуле Пирсона для этих ранжированных данных
#         — он будет называться уже коэффициентом ранговой корреляции Спирмена ρs (Spearman’s rank correlation coefficient).
P_x.y(x3.clean.rang) # корреляции Спирмена ρs для очищенных данных
P_x.y(x3.rang )      # корреляции Спирмена ρsдля данных с выбросами
#         -/ПРИМЕР РЕЗУЛЬТАТА/-:
#
#         Нелинейная монотонная связь               Ранжированные данные
#      700  _______________________           35  ________________________
#          |*                      |             | *                      |
#          |**                     |       в  30 |   *  *                 |
#   в  500 |*                      |       р     |  * *  * *              |
#   р      |*                      |       е  25 |     *  *               |
#   е      |**                     |       м     |    *   *  *            |
#   м  300 | **                    | --->  я  20 |       *  *             |
#   я      |  *                    |       ,     |           *  *         |
#   ,      |   *                   |       р  15 |               *        |
#   м  100 |     *                 |       а     |               * *      |
#   и      |        *              |       н  10 |                   *    |
#   н      |           *           |       г     |                     *  |
#        0 |                      *|       и   5 |                       *|
#           ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾               ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#          30  35  40  45  50  55  60          0   5   10  15  20  25  30 35
#                    пробы, %                            пробы, ранги
# Вопрос 4: Постройте диаграмму рассеяния ранжированных переменных из предыдущего вопроса
#           про вспоминание комбинаций букв, результаты проб отобразите по оси у.
#           Аналогичную диаграмму постройте для исходных данных,
#           где время по оси x отобразите в часах.
#           Расположите диаграмму на одной странице в две колонки.
par(mfrow = c(1, 2))
# 1) Диаграмма рассеяния ранжированных переменных:
plot(x = x3.clean.rang$time, # тревожность по оси Х
y = x3.clean.rang$rememb,
main = "Ранжированные результаты проб,
полученные через каждые 20 минут          ",
xlab = "время, [ранги]",
ylab = "пробы, [ранги]"
)
# 2) Диаграмма исходных данных переменных:
plot(x = x3$time/60, # тревожность по оси Х
y = x3$rememb,
main = "Исходные результаты проб,
полученные через каждые 20 минут          ",
xlab = "время, [ч]",
ylab = "пробы, [%]"
)
# Вопрос 3: Получены данные о проценте воспроизведения комбинаций букв через 20, 40, 60 и т.д. минут после их запоминания: forget.dat
#           (время не записывалось, пробы делались строго через каждые 20 минут).
#           Вычислите меры связи количества вспомненного материала с временем,
#           прошедшим с момента его запоминания:
x3 <- read.csv("C:/Users/ak179/OneDrive/Магистратура/2 КУРС/1 СЕМЕСТР/Лекции (2 курс)/Язык R (шпоры и задачи)/Скрипты/Задание 9/3_4.forget.dat")
# 1) Приведем исходные данные к рабочему виду:
#    1.1) По наблюдениям видно, что есть данные о "пробах", но нет данных о "времени".
head(x3) # посмотрим первые 6 наблюдений
#    1.2) Добавим данные о времени:
x3$time <- seq(0, 20*(nrow(x3)-1), by = 20); head(x3)
#         -/ПРИМЕЧАНИЕ/-:
#         Функция seq() создает вектор с определенным интервалом.
#         Это нужно, чтобы количество наблюдений в стобце "время" совпадало со столбцом "результаты проб".
#         Выражение (nrow(x3)-1) вычисляет коечное число, до которого нужно строить вектор.
#         Т.е. в случае 36 исходных наблюдений, интервал умножаем на (36-1) и получем число 700 на позиции 36.
#    1.3) Построим диаграмму рассеивания:
plot(x3, main = "Диаграмма рассеивания")
#         По диаграмме видно, что оптимальная линия, вокруг которой расположены точки, не прямая.
#         Значит ковариация и коэффициент линейной корреляции перестают быть адекватными мерами связи.
#         Такая нелинейная связь называется - МОНОТОННОЙ.
#
#         Нелинейная монотонная связь
#          _______________________
#         |*                      |     Функция - МОНОТОННАЯ, если направление изменения одной переменной
#         |*                      |     не меняется с возрастанием (убыванием) другой переменной.
#         |*                      |
#         |*                      |     Монотонная связь может быть:
#         |  *                    |     ----------------------------
#         |  *                    |     • либо неубывающей;
#         |    *                  |     • либо невозрастающей.
#         |    *                  |
#         |      *                |     Несмотря такую полную связь, на отсутствие разброса точек вокруг воображаемой линии,
#         |        * *            |     коэффициент их линейной корреляции вновь оказывается по модулю значительно меньше единицы.
#         |            * *        |
#         |                * * * *|     При монотонной связи часто распределения переменных имеют выраженную асимметрию, причём её знаки различаются.
#          ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#    1.4) Определяем ИНДЕКСЫ точек интерактивно по графику:
identify(x3)  # интерактивное определение индексов точек
#    1.5) Очистим таблицу данных от этих наблюдений (выбросов):
x3.clean <- x3[-c(31, 33), ]
# 2) Вычислите меры связи количества вспомненного материала с временем,
#    прошедшим с момента его запоминания при помощи:
#    • коэффициента ρ (коэффициент линейной корреляции ρ Пирсона);
#    • коэффициента ρs коэффициент ранговой корреляции ρs Спирмена).
#
#    2.1) Коэффициент ρ Пирсона:
P_x.y <- function(x.table)
{
x.table <- na.omit(x.table)
sd_x    <- sqrt(sum((x.table[[1]] - mean(x.table[[1]]))^2)/nrow(x.table))
sd_y    <- sqrt(sum((x.table[[2]] - mean(x.table[[2]]))^2)/nrow(x.table))
Σ       <- sum((x.table[[1]]-mean(x.table[[1]]))*(x.table[[2]]-mean(x.table[[2]])))
N.σx.σy <- nrow(x.table)*sd_x*sd_y
return(Σ/N.σx.σy)
}
P_x.y(x3.clean) # - коэффициент ρ для очищенных данных
P_x.y(x3)       # - Коэффициент ρ для данных с выбросами
#         -/ПРИМЕЧАНИЕ/-:
#         Коэффцицент кореляции здесь вышел сильно заниженным, хотя точки почти идут ровно по линии.
#         Это говорит о том, что здесь применялась неправильная мера для данного распределения.
#    2.2) Коэффициент ρs Спирмена:
#
#         Для того, чтобы правильно применить коэффициент кореляции, нужно выпрямить наши данные.
#         Т.е. нужно искуственно выпрямляем распределение, чтобы она налезала на одну прямую и считаем коэффициент корреляции.
#
#         Простой способ избавиться от асимметрии — перевести значения наблюдений каждой переменной в ранги:
#         так мы получим практически равномерные распределения вида “1, 2, 3, 4 …,”
#         где каждое значение будет встречаться лишь однажды, за исключением связанных рангов.
#
x3.clean.rang <- data.frame(rememb = rank(x3.clean$rememb),
time   = rank(x3.clean$time))
(head(x3.clean.rang))
# Сразу делаем ранги для данных с выбросами
x3.rang       <- data.frame(rememb = rank(x3$rememb),
time   = rank(x3$time))
#         Затем вычислим коэффициент корреляции по той же формуле Пирсона для этих ранжированных данных
#         — он будет называться уже коэффициентом ранговой корреляции Спирмена ρs (Spearman’s rank correlation coefficient).
P_x.y(x3.clean.rang) # корреляции Спирмена ρs для очищенных данных
P_x.y(x3.rang )      # корреляции Спирмена ρsдля данных с выбросами
#         -/ПРИМЕР РЕЗУЛЬТАТА/-:
#
#         Нелинейная монотонная связь               Ранжированные данные
#      700  _______________________           35  ________________________
#          |*                      |             | *                      |
#          |**                     |       в  30 |   *  *                 |
#   в  500 |*                      |       р     |  * *  * *              |
#   р      |*                      |       е  25 |     *  *               |
#   е      |**                     |       м     |    *   *  *            |
#   м  300 | **                    | --->  я  20 |       *  *             |
#   я      |  *                    |       ,     |           *  *         |
#   ,      |   *                   |       р  15 |               *        |
#   м  100 |     *                 |       а     |               * *      |
#   и      |        *              |       н  10 |                   *    |
#   н      |           *           |       г     |                     *  |
#        0 |                      *|       и   5 |                       *|
#           ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾               ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#          30  35  40  45  50  55  60          0   5   10  15  20  25  30 35
#                    пробы, %                            пробы, ранги
# Вопрос 4: Постройте диаграмму рассеяния ранжированных переменных из предыдущего вопроса
#           про вспоминание комбинаций букв, результаты проб отобразите по оси у.
#           Аналогичную диаграмму постройте для исходных данных,
#           где время по оси x отобразите в часах.
#           Расположите диаграмму на одной странице в две колонки.
par(mfrow = c(1, 2))
# 1) Диаграмма рассеяния ранжированных переменных:
plot(x = x3.clean.rang$time, # тревожность по оси Х
y = x3.clean.rang$rememb,
main = "Ранжированные результаты проб,
полученные через каждые 20 минут          ",
xlab = "время, [ранги]",
ylab = "пробы, [ранги]"
)
# 2) Диаграмма исходных данных переменных:
plot(x = x3$time/60, # тревожность по оси Х
y = x3$rememb,
main = "Исходные результаты проб,
полученные через каждые 20 минут          ",
xlab = "время, [ч]",
ylab = "пробы, [%]"
)
#    1.1) Диаграмма рассеяния ранжированных переменных:
plot(x = x3.clean.rang$time, # тревожность по оси Х
y = x3.clean.rang$rememb,
main = "Ранжированные результаты проб,
полученные через каждые 20 минут               ",
xlab = "время, [ранги]",
ylab = "пробы, [ранги]"
)
#    1.2) Диаграмма исходных данных переменных:
plot(x = x3$time/60, # тревожность по оси Х
y = x3$rememb,
main = "Исходные результаты проб,
полученные через каждые 20 минут               ",
xlab = "время, [ч]",
ylab = "пробы, [%]"
)
# Вопрос 1: Были измерены и записаны в файл показатели интеллекта и тревожности испытуемых: tests.dat
x1 <- read.csv("C:/Users/ak179/OneDrive/Магистратура/2 КУРС/1 СЕМЕСТР/Лекции (2 курс)/Язык R (шпоры и задачи)/Скрипты/Задание 9/1_2.tests.dat")
head(x1) # посмотрим первые 6 наблюдений
# -/МОРАЛЬ/-
# "Смотри сначала на диаграмму, прежде чем считать коэффициенты"
# 1) Построим диаграмму рассеивания:
plot(x1, main = "Диаграмма рассеивания")
#    ВЫБРОСЫ хорошо видны на диаграмме в виде точек:
#    а) далеко отстоящих от общего облака рассеивания;
#    б) лежащих также далеко от линии идеальной линейной корреляции.
#
#           Диаграмма рассеивания
#           _____________________
#       260|  *                 *|
#          | * <-выбросы     * * |
#    A  240|*            *   *   |
#    n     |            *  *  *  |
#    x  220|          *  * *     |
#    i     |     *  *  *  *      |
#    e  200|      *   *  *       |
#    t     |   *   *             |
#    y  180|    * *              |
#          |  *                  |
#       160|                     |
#           ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#          70   85   100  115  130
#
#                  IQ
#
#    ρ Пирсона - коэффициент линейной корреляции ρ Пирсона
#
#    Идеальная положит. кор-ция.      Идеальная отриц. кор-ция.        Нет линейной корреляции
#           ρ Пирсона = 1                   ρ Пирсона = -1                  ρ Пирсона = 0
#     _________________________       _________________________       _________________________
#    |                        *|     |*                        |     |                         |
#    |                      *  |     |  *                      |     |    *       *     *      |
#    |                    *    |     |    *                    |     |       *             *   |
#    |                  *      |     |      *                  |     |  *       *     *    *   |
#    |                *        |     |        *                |     |      *                  |
#    |              *          |     |          *              |     |  *        *    *     *  |
#    |            *            |     |            *            |     |    *        *           |
#    |          *              |     |              *          |     |          *       *      |
#    |        *                |     |                *        |     |     *       *      *    |
#    |      *                  |     |                  *      |     |  *    *        *        |
#    |    *                    |     |                    *    |     |          *           *  |
#    |  *                      |     |                      *  |     |  *     *   *      *     |
#    |*                        |     |                        *|     |                         |
#     ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾       ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾       ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
# 2) Удаление выбросов:
#    2.1) Определяем ИНДЕКСЫ точек интерактивно по графику:
#         Поскольку наши меры связи чувствительны к выбросам,
#         мы решаем описать выбросы отдельно и удалить из
#         дальнейшего анализа как не вписывающиеся в общую картину.
#         Для ОПИСАНИЯ и УДАЛЕНИЯ наблюдений нам нужно знать их индексы (номера строк).
identify(x1)  # интерактивное определение индексов точек
#         -/ПРИМЕЧАНИЕ/-:
#         После применение команды "identify()" появится возможность      P.s: можно этот край просто закликать до предупреждения:
#         "щелчком" отмечать прямо на диаграмме интересующие точки.       "ближайшая точка уже определена", а не точечно выцеливать
#         Для ОТМЕНЫ - нажать кнопку "Esc".
#
#                 Диаграмма рассеивания
#                 _____________________
#             260|  *30               *|
#                | *17  <- индексы, а не "x" или "y" !
#          A  240|*5                   |
#          n     |            *  *  *  |
#          x  220|          *  * *     |
#          i     |     *  *  *  *      |
#          e  200|      *   *  *       |
#          t     |   *   *             |
#          y  180|    * *              |
#                |  *                  |
#             160|                     |
#                 ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#                70   85   100  115  130
#
#                          IQ
#
#         Результат в Console:
#         [1]  5 17 30
#    2.2) Очистим таблицу данных от этих наблюдений (выбросов):
x1.clean <- x1[-c(5, 17, 30), ]
#         -/ПРИМЕЧАНИЕ/-:
#         Вектор со знаком “минус” составляем из индексов наблюдений-выбросов,
#         подлежащих исключению — их фильтр [] отбрасывает.
#         Индекс столбца, j не указан (после запятой пусто) — берутся оба столбца таблицы.
#         Результат сохраняем в новой таблице x1.clean
#                Диаграмма рассеивания
#                _____________________
#            260|                    *|
#               |   <- выбросы были очищены!
#         A  240|                     |
#         n     |            *  *  *  |
#         x  220|          *  * *     |
#         i     |     *  *  *  *      |
#         e  200|      *   *  *       |
#         t     |   *   *             |
#         y  180|    * *              |
#               |  *                  |
#            160|                     |
#                ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
#               70   85   100  115  130
#
#                         IQ
#    2.3) Убедимся, что выбросы исчезли:
plot(x1.clean, main = "Диаграмма рассеивания")
#
#    2.4) Перед расчетами посмотрим сводку по таблице и проверим её:
summary(x1.clean)
#         -/ПРИМЕР/-:
#         IQ           Anxiety
#         Min.   : 73.0   Min.   :156.0
#         1st Qu.: 90.5   1st Qu.:191.0
#         Median :101.0   Median :202.0
#         Mean   :101.6   Mean   :202.8
#         3rd Qu.:108.0   3rd Qu.:211.5
#         Max.   :133.0   Max.   :253.0
#         -----------------------------
#         NA's   :2       NA's   :2
#         -----------------------------
#    2.5) Для нормальной работы с данными избавимся от пропущенных строк (избавимся от NA):
x1.clean <- na.omit(x1.clean); summary(x1.clean)
#         -/ВАЖНО/-:
#         НЕ ПРИМЕНЯТЬ функцию na.omit() ДО очистки от выбросов, иначе индексы сдвинуться!
# 3) Определите, насколько в этих данных сильно связаны
#    показатели интеллекта и тревожности, при помощи:
#    • ковариации Cov;
#    • коэффициента ρ.
#
#
#    -/ОБЩАЯ ТЕОРИЯ/-
#    Корреляция, корреляционная зависимость — взаимозависимость  двух или нескольких случайных величин.
#    Суть ее заключается в том, что при изменении значения одной переменной происходит закономерное изменение
#    (уменьшению или увеличению) другой(-их) переменной(-ых).
#
#
#    3.1) Ковариация Cov (мера совместной изменчивости (ЛИНЕЙНОЙ связи) двух случайных величин):
#
#         Мы будем выяснять, какая из тенденций преобладает:
#         • переменные изменяются однонаправленно  - ковариация положительная (+) (при росте одной вторая тоже увеличивается);
#         • переменные изменяются разнонаправленно - ковариация отрицательная (-) (если одна растёт, вторая уменьшается).
#
#         Для сопоставления тенденций разделим наблюдения каждой переменной на две группы:
#         • выше среднего;
#         • ниже среднего.
#
#           Диаграмма рассеивания      Это удобно сделать, ЦЕНТРИРОВАВ переменные, где:
#           _____________________      • в группу "выше среднего" — войдут положительные значения переменной;
#          |"2"*      |      *"1"|     • в группу "ниже среднего" — войдут отрицательные значения переменной.
#         6| *        |   *  *   |
#          |*         |* *  *    |     Если распределение симметрично, то наблюдений в двух группах окажется примерно ПОРОВНУ.
#         3|          |*  *      |
#          |      * * |  * *     |     Комбинируя знаки двух переменных, всего мы получим четыре группы наблюдений,
#         0|------*-- |-*--*-----|     которые на диаграмме оказываются в разных квадрантах (четвертях) системы координат:
#          |     *  * |  *       |
#        -3|   * * *  |          |     Наблюдения 1-го и 3-го квадрантов представляют тенденцию прямой связи переменных:
#          |  * * *   |          |     • обе отклоняются от центра в одну сторону (обе в большую либо в меньшую).
#        -6|  *       |          |
#          |"3"       |       "4"|     Наблюдения 2-го и 4-го представляют соответственно обратную тенденцию:
#           ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾      • переменные отклоняются в противоположные стороны.
#          -20  -10   0   10   20
#
#         Ковариация отражает как частоту, так и величину проявлений каждой тенденции.
#         Знак и величина ковариации указывают на:
#         ----------------------------------------
#         • преобладающую тенденцию;
#         • на степень её выраженности;
#         • силу.
#         Формула:                           |   -/Ковариация простыми словами/-
#                    N                       |   -------------------------------
#                    Σ  (Xᵢ - μₓ)(yᵢ - μᵧ)   |   Ковариация — это мера того, как две случайные величины изменятся при сравнении друг с другом.
#                   i=1                      |   ковариация — это разница между двумя тенденциями: прямым и обратным соотношением признаков.
#         Cov x,y = ——————————————————————   |   • Положительная ковариация - переменные одновременно увеличиваются или уменьшаются.
#                             N              |   • Отрицательная ковариация - одна переменная растёт, вторая уменьшается.
#                                            |   • Нулевая       ковариация - отсутствие линейной взаимосвязи.
#
#         Ковариация может измерять движения двух переменных, но не указывает на степень,
#         в которой эти две переменные изменяются по отношению друг к другу.
Cov_x.y <- function(x.table)
{
x.table <- na.omit(x.table)
Σ <- sum(                                     # сложив все эти произведения, мы получим разность двух сумм:
(x.table[[1]]-mean(x.table[[1]])) *  # (а) произведений отклонений в одном направлении;
(x.table[[2]]-mean(x.table[[2]]))    # (б) произведений отклонений в противоположных.
)
N <- nrow(x.table)  # Нормируем эту разность на объём наблюдений N - найдём среднее произведение отклонений переменных по каждому наблюдению (ковариация)
return(Σ/N)
}
Cov_x.y(x1.clean)
#         -/ПРИМЕЧАНИЕ/-:
#         Заметим, что формула КОВАРИАЦИИ похожа на формулу ДИСПЕРСИИ.
#         Если линейной связи между переменными нет, то ни одна из тенденций не преобладает (xᵢ=yᵢ), => (Cov = σ2).
#         Таким образом, ковариацию можно рассматривать как совместную дисперсию двух случайных величин,
#         а дисперсию — как частный случай ковариации, когда рассматривается ковариация величины самой с собой.
#    3.2) Коэффициент ρ (коэффициент линейной корреляции ρ Пирсона):
#         У "ковариации" есть ПРОБЛЕМА - она зависи от масштаба каждой из переменных.
#         -/ПРИМЕР/-:
#         • если возьмем   x в [мм] - одно   значение ковариации;
#         • если переведем x в [м]  - другое значение ковариации.
#         Кроме того, в таком виде нельзя сравнивать силу связи пар переменных,
#         имеющих разные единицы измерения.
#         Это не очень удобно, поэтому в дополнение к центрации ещё проводим НОРМИРОВАНИЕ,
#         т.е. стандартизуем обе переменные. Т.е. просто делим еще и на стандартыне отклонения x и y.
#
#                  N  (Xᵢ - μₓ) (yᵢ - μᵧ)    N                       |   -/Кратко о "ρ Пирсона"/-
#                  Σ  ————————— —————————    Σ  (Xᵢ - μₓ)(yᵢ - μᵧ)   |   -------------------------------
#                 i=1    σx        σy       i=1                      |   максимальное значение ρ Пирсона = "1"  (полная положительная линейная корреляция);
#         P x,y = ——————————————————————— = ——————————————————————   |   минимальное  значение ρ Пирсона = "−1" (полная отрицательная линейная корреляция);
#                            N                     N σx σy           |   среднее      значение ρ Пирсона = "0"  (отсутсвие линейной корреляции).
P_x.y <- function(x.table)
{
x.table <- na.omit(x.table)
sd_x    <- sqrt(sum((x.table[[1]] - mean(x.table[[1]]))^2)/nrow(x.table))
sd_y    <- sqrt(sum((x.table[[2]] - mean(x.table[[2]]))^2)/nrow(x.table))
Σ       <- sum((x.table[[1]]-mean(x.table[[1]]))*(x.table[[2]]-mean(x.table[[2]])))
N.σx.σy <- nrow(x.table)*sd_x*sd_y
return(Σ/N.σx.σy)
}
P_x.y(x1.clean)
P_x.y(x1)
#    3.2) Резюме по ковариации и линейной корреляции Пирсона:
#         ---------------------------------------------------
#         Ковариация и коэффициент линейной корреляции Пирсона описывают выраженность, или тесноту линейной связи,
#         т.е. то, насколько одна переменная имеет тенденцию изменяться прямо или обратно пропорционально другой.
#         В частности, на диаграмме ρ Пирсона описывает, насколько точки данных
#         близко расположены к воображаемой прямой, которую можно через них провести.
#         Если оптимальная линия, вокруг которой расположены точки, не прямая,
#         ковариация и коэффициент линейной корреляции перестают быть адекватными мерами связи.
# Вопрос 2:
# 1) Постройте диаграмму рассеяния по данным из предыдущего вопроса,
#    отобразив по оси x тревожность.
plot(x = x1.clean$Anxiety, # тревожность по оси Х
y = x1.clean$IQ,
main = "Диаграмма рассеивания",
xlab = "тревожность",
ylab = names(x1.clean[1]),  # names(x1.clean[1]) - название первого столбца
)
# Определите, насколько в этих данных сильно связаны показатели интеллекта и тревожности, при помощи:
# ковариации Cov: 196.9274
# коэффициент ρ: 0.7338272
# Для сравнения вычислите ρ, не удаляя выбросов, по исходным данным:
# коэффициент ρ: 0.2092865
# 2) Опишите представленное на диаграмме двумерное распределение,
#    при этом коэффициент линейной корреляции Пирсона интерпретируйте, руководствуясь таблицей:
#    модуль коэффициента	связь
#    < 0.1	не выражена
#    ≥ 0.1	слабая
#    ≥ 0.3	умеренная
#    ≥ 0.5	тесная
# -/ШАБЛОН ДЛЯ ОТВЕТА/- (на мой взгляд)
#
# Характеристики диаграммы:
# -------------------------
#   • наклон (направление связи):
#     a) положительная линейная зависимость (1,3 квадрант),
#     б) отрицательная линейная зависимость (2,4 квадрант),
#     в) переменные линейно независимы друг от друга
#
#   • ширина (сила, теснота связи)
#
#     Сила связи - абсолютное значение коэффициента корреляции Пирсона
#
#     О силе связи можно судить по тому, насколько тесно расположены точки-объекты около
#     линии регрессии - чем ближе точки к линии, тем сильнее связь
#
# -/МОЙ ОТВЕТ/-
# Данное двумерное распределение по диаграмме имеет форму облака рассеивания, по форме приближающееся к идеальной линии, т.е. наблюдается линейная корреляция. Это подтверждает высокий коэффициент линейной корреляции ρ Пирсона равный 0.7338272, который показывает, что между переменными наблюдается тесная связь.
# Положительный знак ρ говорит о том, что корреляция положительна, т.е. показатели тревожности и интеллекта изменяются однонаправленно (расположены в 1-ом и 3-ем квадрантах) и представляют тенденцию прямой связи между переменными.
plot(x = x1.clean$Anxiety, # тревожность по оси Х
y = x1.clean$IQ,
main = "Результаты показателей
интеллекта и тревожности испытуемых     ",
xlab = "тревожность",
ylab = names(x1.clean[1]),  # names(x1.clean[1]) - название первого столбца
)
