# Вопрос 1: В ходе тестирования случайно выбранных студентов вуза 
#           получены данные об их успеваемости (% усвоенного учебного материала)

file <- "1_3.sample1.dat"
x2 <- read.csv(paste0(dirname(rstudioapi::getSourceEditorContext()$path), "/", file)); rm(file)


# 1) Посмотрим данные:
     head(x2); str(x2)
     
# 2) Задание:
     
#    2.1) По этим данным:
     
#         • Найдите сводные характеристики распределения 
#           успеваемости этих студентов.
          
#         • Оцените параметры распределения успеваемости всех студентов 
#           вуза, используя несмещённые точечные оценки (статистики).
#                           ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯         
#         • Выполните аналогичные вычисления, 
#           используя функции R: mean(); var(); sd(). 
#           Укажите, по какой формуле действует каждая из этих функций.
          
     
#         -/ТЕОРИЯ/-
#         ------------------ 
#         СТАТИЧЕСКИЙ ВЫВОД:
#         ------------------    
#         «НАДЁЖНОСТЬ», или «ТОЧНОСТЬ» статистического вывода зависит от того, 
#         насколько выборка репрезентативна, то есть адекватно представляет генеральную совокупность.     
#                                                    ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯        
#         Наверняка этого знать НЕ можем, но теоретически ожидаемая репрезентативность максимальна, 
#         если все наблюдения генеральной совокупности имеют РАВНУЮ вероятность попасть в выборку
#         — такая выборка называется случайной (random sample). 
#                                    ¯¯¯¯¯¯¯¯¯   
#               Т.е.
#               ----------------------------------------------------------------------------------         
#               • Весь частотный статистический вывод строится на допущении о случайности выборки.
#                                ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯                ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯   
#               • Надёжность вывода зависит и от объёма выборки.
#                 ¯¯¯¯¯¯¯¯¯¯                     ¯¯¯¯¯¯¯¯¯¯¯¯¯¯
     
#         ----------------------------           
#         Школы статистического вывода     
#         ---------------------------- 
#         • «частотный», или классический подход строится на статистическом, или объективном определении вероятности 
#            как относительной частоты события при бесконечном числе наблюдений.   
     
#         • «Байесовский» подход использует субъективное определение: вероятность —
#            это степень нашей уверенности в неизвестном нам исходе события, потенциального либо уже произошедшего. 
     
#         В ДАННОМ ЗАДАЧЕ «ЧАСТОТНЫЙ ПОДХОД»! 
     
     
#         2.1.1) Напишем функцию, которая выдаст таблицу со всеми ответами:  
                 x.Stat <- function(vectot, var=NULL){
                   a<-1
           
#         В статистическом выводе анализируем изменчивость признаков при частотном подходе 
#         имея дело с двумя распределениями одной и той же переменной: 
#         - c распределением генеральной совокупности и выборки.
#             • Сводные характеристики распределения генеральной совокупности называются параметрами; 
#             • аналогичные выборочные характеристики — статистиками.
                   
#         • Генеральная совокупность (population) - множество всех потенциальных наблюдений изучаемого явления 
#         • Выборка (sample) - имеющиеся у нас данные — это наблюдения, выборочно полученные из генеральной совокупности.
               
                   
#               • Параметры - то, что хотим оценить (не можем их вычилсить, но в районе какого значения указать);
#               • Статистики - то, что можем вычислить;                    
                       
#         2.1.2) Характеристика (Сводные характеристики распределения генеральной совокупности):  
                  
                 μ  <- mean(vectot[[a]]); μ
                 
#                • Несмещённость (unbiasedness) оценки — это свойство её математического ожидания 
#                  (теоретического среднего) совпадать с истинным значением параметра.
                 
#                  Выборочная доля градации переменной — это несмещённое (unbiased) средство оценивания её доли в генеральной совокупности. 
#                  Несмещёнными оценками соответствующих параметров служат также выборочное среднее и некоторые другие статистики.
                 
                 σ2 <- sum((vectot[[a]] - mean(vectot[[a]]))^2)/length(vectot[[a]]); σ2
                 σ  <- sqrt(σ2); σ
                 
       
#         2.1.3) Статистика:
                 
#                Нас интересует распределение генеральной совокупности и его параметры, 
#                но можем найти только их приблизительные значения.
#                (приближённые вычисления называются оцениванием (estimation)).
                 
                 x  <- sum(vectot[[a]])/(length(vectot[[a]])); vectot
                 s2 <- var(vectot[[a]]); s2
                 s  <- sd(vectot[[a]]); s
       
#         2.1.4) Функция R
                 if (μ == x ) {R.μ.x   <-"совпадают"}
                 if (σ2== s2) {R.σ2.s2 <-"совпадают"} 
                 if (σ == s ) {R.σ.s   <-"совпадают"} 
                 
                 if (μ  < x ) {R.μ.x   <-"выборочное"} 
                 if (σ2 < s2) {R.σ2.s2 <-"выборочное"} 
                 if (σ  < s ) {R.σ.s   <-"выборочное"} 
                 
                 if (μ  > x ) {R.μ.x   <-"генеральное"} 
                 if (σ2 > s2) {R.σ2.s2 <-"генеральное"} 
                 if (σ  > s ) {R.σ.s   <-"генеральное"}                  
                
                 x.DF <- data.frame("характеристика"= c(μ, σ2, σ), 
                                    "статистика"    = c(x, s2, s),
                                    "Функция R"     = c(R.μ.x, R.σ2.s2, R.σ.s))
         
                 if (is.null(var)) {return(x.DF)}
                 if (var=="μ")     {return(μ)}
                 if (var=="σ2")    {return(σ2)}
                 if (var=="σ")     {return(σ)}
                 if (var=="x")     {return(x)}
                 if (var=="s2")    {return(s2)}
                 if (var=="s")     {return(s)}}
          
#         2.1.5) Ответ:                 
                 x.Stat(x2)
          
     
#    2.2) Оцените по этой выборке стандартные ошибки:  
           
#         При статистическом оценивании выяснить, насколько полученная оценка точна.
#         Точность оценки выражается через её расхождение с истинным значением параметра.        
#         Оно нам неизвестно, поэтому выяснить, насколько точна наша выборочная оценка, мы не можем, 
#         но зато можем определить, насколько расходятся такие выборочные оценки в целом, каков их разброс.          
#                                   ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯              
#            В качестве меры разброса используется «стандартное отклонение». 
#            Теоретически для его вычисления должны извлечь из генеральной совокупности бесконечное число 
#            случайных выборок и по каждой из них оценить параметр, т.е. найти для каждой выборки соответствующую статистику. 
#            Так мы получим множество значений статистики, которое имеет своё распределение — выборочнле распределение (sampling distribution).        
#                                                                                             ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯                 
#         Если статистика является несмещённым средством оценивания, то 
#         • центр её выборочного распределения и есть истинное значение параметра, 
#         • а отклонение конкретной оценки от центра интерпретируется как величина её неточности, ошибки.
                 
#         Стандартное отклонение выборочного распределения называется стандартной ошибкой SE.
                 
#         Формулы SE описывает насколько точно получается оценить неизвестный параметр по выборочному значению (по статистике).
                                  
#         2.2.1) Cтандартная ошибка выборочного среднего SEM:
#                ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
#                Стандартная ошибка среднего, SEM — это максимальная величина, на которую оценка посредством выборочного среднего 
#                отклоняется от значения среднего данной генеральной совокупности примерно в 2/3 выборок такого же объёма.

#                Стандартная ошибка среднего, SEM - это максимальная величина, в пределах которой отклоняется от генерального среднего 2/3 выборочных средних.
#                т.е. берем много выборок и считаем много средних и смотрим как средние распределяются.
#                И, оказывается, 2/3 средних будут лежать в интервале от "-" до "+" 1 стандартная ошибка от генерального среднего.
                 
#                Т.е. SEM - стандартное отклонение среднего, которое принято называть стандартной ошибкой, 
#                потому что, когда оцениваем, интепретируем отклонение нашей оценки как её ошибку. Чем больше октлоняется, тем сильнее ошибаемся.                     

#                Т.е. если будем таким способом оценивать, то в 2/3 случаев наш результат +- 1 стандартное отклоение от генерального отклонения.                          
                 
                 n  <- length(x2[[1]])
                 σ  <- x.Stat(x2, "σ")
                 s  <- x.Stat(x2, "s")
                 
                 SEM_σ <- σ/sqrt(n);  SEM_σ
#                Формула дает точное значение стандартной ошибки, но 
#                недостаток: σ — это генеральное стандартное отклонение.
                 
#                Мы не можем пользоваться этой формулой, т.к.СИГМА не известна - это параметр. Мы не можем использвать их для вычислений.
#               • Параметры - то, что хотим оценить (не можем их вычилсить, но в районе какого значения указать);
#               • Статистики - то, что можем вычислить;                 
                
                 
#                Вместо него использовать его несмещённую оценку 
#                — исправленное стандартное отклонение выборки:
                 SEM_s <- s/sqrt(n);  SEM_s
          
#                -/ПРИМЕЧАНИЕ/-   
#                Поскольку в последнюю формулу входит не σ, а её оценка, то и 
#                практически вычисляемая стандартная ошибка — это не истинное значение параметра, 
#                а его оценка, статистика. Глядя на формулу, мы также замечаем, что 
#                чем меньше разброс наблюдений переменной и больше объём выборки, тем меньше SEM, 
#                т.е. выше точность оценки среднего.
                 
                 
              
#         2.2.2) Доля студентов вуза, чья успеваемость не превышает 58%:
#                ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯    
#                p - доля (proportion) 
                 p <- pnorm(59, mean = mean(x2[[1]]), sd = x.Stat(x2, "σ"))
                 
#         2.2.3) Стандартная ошибку такой выборочной доли SEp:
#                ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
#                При оценивании доли p (proportion) мы можем перекодировать данные как бинарные, 
#                по признаку наличия либо отсутствия “успеха,” т.е. одной из градаций. 
#                В таком случае долю можно рассматривать как среднее нулей и единиц, 
#                и, если выборка не слишком маленькая, то его выборочное распределение оказывается близким к нормальному.
                 
#                SS = pn × (1-p)² + (1-p)n × (0-p)²
#                 
#                     pn(1-p)² + (1-p)np²   pn(1-p)((1-p)+p)
#                σ² = ——————————————————— = ———————————————— = p(1-p)
#                              n                   n
                 SS <- (p*n) * (1-p)^2 + ((1-p)*n * (0-p)^2)
                 σ2 <- p*(1-p)
                 
                 SEp <- sqrt(σ2/n);  SEp
                 
#               Интерпретируется SEp аналогично SEM, как наибольшее отклонение выборочной 
#               доли от доли генеральной совокупности примерно в 2/3 выборок такого же объёма.
                 
                
#               Как интепретировать стандартную ошибку? Есть проблема, 
#               есть параметр, который хотим оценить и у него не может быть ошибки,
#               это константа.
   
#               У нас есть наши данные, по которым посчитали статистику - являются константами и случайно изменятся не могут.
#               Как можем представить себе, что там может случайно меняться?
#               Мы будем набирать много выборок из генеральной совокупности и по каждой выборке оценивать параметры.  

                               
#    2.3) Найдите для такой выборочной доли статистическую погрешность MOE с CL = 95%:
         
#         При интепретации SEM говорили, что если будем таким способом оценивать, то в 2/3 случаев наш результат +- 1 стандартное отклоение от генерального отклонения. 2/3 выборочных средних попадает.                          
#         Это не очень удобно и понятно, поэтому возьмем другой интервал. Это уже не стандартная ошибка, а статистическая погрешность.
#         Она аналогична по смыслу, тоже есть граничные значения, за пределых которых не выходят определнное число наблюдений,
#         только не 68%, а можно задать любую долю (обычно 90-95%)
                          
#         MOE = (o - z) × SE    
                 
#         2.3.1) Находим для заданного уровня доверия CL вероятность ⍺: ⍺=1-CL
                 CL <- 0.95
                 a <- 1-CL
                 
#         2.3.2) Находим квантиль стандартного нормального распределения 0.5⍺ и отнимем от 0,
#                т.е. меняем знак на положительный     
                 z <- qnorm(0.5*a)
          
#         2.3.3) Переводим найденную величину в значение исходной шкалы, умножим её на SE.
#                Проученный результат - погрешность с уровнем доверимем ⍺.
                 MOE <- (0-z) * SEp;  MOE
                 
      
#    2.4) Определите, какой нужен объем выборки, чтобы погрешность оценки доли уменьшить:

#         в 2 раза: (т.е. n при котором MOE/2 от изначального n)
#         в 3 раза: (т.е. n при котором MOE/3 от изначального n)

#         Для решения вернитесь к строке с формулой n  <- length(x2[[1]]) и прибавляйте к ней числа.

#         Например:
#         n  <- length(x2[[1]]) + 120
#         n  <- length(x2[[1]]) + 320
                 
#         и смотрите, какое значение MOE получается после выполнения всего скрипта. 
#         В данном случае правильные ответы: 160, 360
                 
                 
                 

                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
        
